{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e682f94b",
   "metadata": {},
   "source": [
    "# Calculating the Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65d62cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written points info to C:\\Point Detection\\preprocessing\\processed\\receipt_points.json\n",
      "{\n",
      "  \"store_name_raw\": \"Holiland\",\n",
      "  \"matched_store\": \"Holiland Travel\",\n",
      "  \"bucket\": \"餐饮\",\n",
      "  \"total_price\": 74.0,\n",
      "  \"points\": 74\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import difflib\n",
    "import psycopg2\n",
    "from decimal import Decimal, ROUND_DOWN\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ─── 0) Setup & load ───────────────────────────────────────────────────\n",
    "load_dotenv(r\"C:\\Point Detection\\.env\")\n",
    "DSN = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "# ─── 1) Read parsed summary ────────────────────────────────────────────\n",
    "summary_path = r\"C:\\Point Detection\\preprocessing\\processed\\parsed_summary.json\"\n",
    "with open(summary_path, encoding=\"utf-8\") as f:\n",
    "    summary = json.load(f)\n",
    "\n",
    "store_name  = summary[\"store_name\"]\n",
    "total_price = Decimal(str(summary[\"total_price\"]))\n",
    "\n",
    "# ─── 2) Connect & load store_categories ───────────────────────────────\n",
    "conn = psycopg2.connect(DSN)\n",
    "cur  = conn.cursor()\n",
    "cur.execute(\"SELECT store_name, bucket FROM store_categories;\")\n",
    "store_map  = dict(cur.fetchall())\n",
    "store_keys = list(store_map.keys())\n",
    "\n",
    "# ─── 3) Fuzzy-match (strict) ───────────────────────────────────────────\n",
    "matches = difflib.get_close_matches(store_name, store_keys, n=1, cutoff=0.6)\n",
    "if not matches:\n",
    "    raise ValueError(f\"No matching store for {store_name!r}\")\n",
    "best_store  = matches[0]\n",
    "best_bucket = store_map[best_store]\n",
    "\n",
    "# ─── 4) Compute points ────────────────────────────────────────────────\n",
    "if best_bucket in (\"零售\", \"餐饮\"):\n",
    "    points = int(total_price)\n",
    "else:\n",
    "    points = int((total_price / Decimal(5)).to_integral_value(rounding=ROUND_DOWN))\n",
    "\n",
    "# ─── 5) Build output & write JSON ──────────────────────────────────────\n",
    "result = {\n",
    "    \"store_name_raw\": store_name,\n",
    "    \"matched_store\":  best_store,\n",
    "    \"bucket\":         best_bucket,\n",
    "    \"total_price\":    float(total_price),\n",
    "    \"points\":         points\n",
    "}\n",
    "\n",
    "out_path = r\"C:\\Point Detection\\preprocessing\\processed\\receipt_points.json\"\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Written points info to {out_path}\")\n",
    "print(json.dumps(result, ensure_ascii=False, indent=2))\n",
    "\n",
    "# ─── 6) Cleanup ───────────────────────────────────────────────────────\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26773928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
