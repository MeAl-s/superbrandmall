{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73d692c4",
   "metadata": {},
   "source": [
    "# Login to superbrandmall database receipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a87c1e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=138.0.7204.157)\nStacktrace:\n\tGetHandleVerifier [0x0x7ff7811a2585+76709]\n\tGetHandleVerifier [0x0x7ff7811a25e0+76800]\n\t(No symbol) [0x0x7ff780f79b2a]\n\t(No symbol) [0x0x7ff780f51f21]\n\t(No symbol) [0x0x7ff780fff56e]\n\t(No symbol) [0x0x7ff78101fd12]\n\t(No symbol) [0x0x7ff780ff7f93]\n\t(No symbol) [0x0x7ff780fc10e1]\n\t(No symbol) [0x0x7ff780fc1e73]\n\tGetHandleVerifier [0x0x7ff781482dad+3093453]\n\tGetHandleVerifier [0x0x7ff78147d13d+3069789]\n\tGetHandleVerifier [0x0x7ff78149ba7d+3195037]\n\tGetHandleVerifier [0x0x7ff7811bc2ce+182510]\n\tGetHandleVerifier [0x0x7ff7811c3bef+213519]\n\tGetHandleVerifier [0x0x7ff7811aadc4+111588]\n\tGetHandleVerifier [0x0x7ff7811aaf79+112025]\n\tGetHandleVerifier [0x0x7ff7811924f8+11032]\n\tBaseThreadInitThunk [0x0x7ffbfdf3e8d7+23]\n\tRtlUserThreadStart [0x0x7ffbfe6dc34c+44]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNoSuchWindowException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m time.sleep(\u001b[32m2\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Fill in username and password\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43musername\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.send_keys(USERNAME)\n\u001b[32m     24\u001b[39m driver.find_element(By.CSS_SELECTOR, \u001b[33m'\u001b[39m\u001b[33minput[placeholder=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mÂØÜÁ†Å\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m]\u001b[39m\u001b[33m'\u001b[39m).send_keys(PASSWORD)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# üîΩ Click the orgId field to auto-trigger selection\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Point Detection\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:922\u001b[39m, in \u001b[36mWebDriver.find_element\u001b[39m\u001b[34m(self, by, value)\u001b[39m\n\u001b[32m    919\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m NoSuchElementException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot locate relative element with: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mby.root\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    920\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m elements[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43musing\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Point Detection\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:454\u001b[39m, in \u001b[36mWebDriver.execute\u001b[39m\u001b[34m(self, driver_command, params)\u001b[39m\n\u001b[32m    451\u001b[39m response = cast(RemoteConnection, \u001b[38;5;28mself\u001b[39m.command_executor).execute(driver_command, params)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m     response[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._unwrap_value(response.get(\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Point Detection\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:232\u001b[39m, in \u001b[36mErrorHandler.check_response\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    230\u001b[39m         alert_text = value[\u001b[33m\"\u001b[39m\u001b[33malert\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[31mNoSuchWindowException\u001b[39m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=138.0.7204.157)\nStacktrace:\n\tGetHandleVerifier [0x0x7ff7811a2585+76709]\n\tGetHandleVerifier [0x0x7ff7811a25e0+76800]\n\t(No symbol) [0x0x7ff780f79b2a]\n\t(No symbol) [0x0x7ff780f51f21]\n\t(No symbol) [0x0x7ff780fff56e]\n\t(No symbol) [0x0x7ff78101fd12]\n\t(No symbol) [0x0x7ff780ff7f93]\n\t(No symbol) [0x0x7ff780fc10e1]\n\t(No symbol) [0x0x7ff780fc1e73]\n\tGetHandleVerifier [0x0x7ff781482dad+3093453]\n\tGetHandleVerifier [0x0x7ff78147d13d+3069789]\n\tGetHandleVerifier [0x0x7ff78149ba7d+3195037]\n\tGetHandleVerifier [0x0x7ff7811bc2ce+182510]\n\tGetHandleVerifier [0x0x7ff7811c3bef+213519]\n\tGetHandleVerifier [0x0x7ff7811aadc4+111588]\n\tGetHandleVerifier [0x0x7ff7811aaf79+112025]\n\tGetHandleVerifier [0x0x7ff7811924f8+11032]\n\tBaseThreadInitThunk [0x0x7ffbfdf3e8d7+23]\n\tRtlUserThreadStart [0x0x7ffbfe6dc34c+44]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Credentials\n",
    "USERNAME = \"cpit\"\n",
    "PASSWORD = \"@abc1234\"  # Replace with your real password\n",
    "\n",
    "# Setup ChromeDriver\n",
    "service = Service(executable_path=\"C:/Point Detection/chromedriver/chromedriver.exe\")\n",
    "options = Options()\n",
    "options.add_argument('--start-maximized')\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Open the login page\n",
    "driver.get(\"https://hddc01.superbrandmall.com/pod-web/static/index.html#/login\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Fill in username and password\n",
    "driver.find_element(By.ID, \"username\").send_keys(USERNAME)\n",
    "driver.find_element(By.CSS_SELECTOR, 'input[placeholder=\"ÂØÜÁ†Å\"]').send_keys(PASSWORD)\n",
    "\n",
    "# üîΩ Click the orgId field to auto-trigger selection\n",
    "driver.find_element(By.ID, \"orgId\").click()\n",
    "time.sleep(1)  # Give it a second to process the selection\n",
    "\n",
    "# ‚úÖ Click the login button\n",
    "driver.find_element(By.ID, \"loginId\").click()\n",
    "\n",
    "# Optional wait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cfea3f",
   "metadata": {},
   "source": [
    "# Going to Receipt Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8ca0494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# Wait helper\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "time.sleep(10)  # wait briefly for submenu to appear\n",
    "\n",
    "# 1. Click ‚ÄúÂ∞èÁ•®Â§ÑÁêÜ‚Äù\n",
    "xpd_div = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[text()=\"Â∞èÁ•®Â§ÑÁêÜ\"]')))\n",
    "time.sleep(30)  # wait briefly for submenu to appear\n",
    "\n",
    "xpd_div.click()\n",
    "\n",
    "# 2. Click ‚Äú‰∫§ÊòìÂ∞èÁ•®‚Äù under submenu\n",
    "receipt_div = wait.until(EC.element_to_be_clickable((By.XPATH, '//div[text()=\"‰∫§ÊòìÂ∞èÁ•®\" and contains(@class, \"subMenu\")]')))\n",
    "receipt_div.click()\n",
    "time.sleep(30)  # wait for the table page to load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae34667b",
   "metadata": {},
   "source": [
    "# Selecting 300 rows (not necessary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd9fcc",
   "metadata": {},
   "source": [
    "to avoid website spam so lesser pages however the limitation is that there's no last page detected since our model starts from last page and the last page I think can only be generated through if there's more than 1 pages so 300 pages is too much\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e34e3",
   "metadata": {},
   "source": [
    "#Start Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb9fa2",
   "metadata": {},
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "def select_300_rows_per_page():\n",
    "    try:\n",
    "        print(\"üõ†Ô∏è Selecting 300 rows per page...\")\n",
    "        # Wait until dropdown appears\n",
    "        dropdown = wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, '//select[@ng-show=\"showSelect\"]')\n",
    "        ))\n",
    "        dropdown.click()\n",
    "\n",
    "        # Click the option with value \"300\"\n",
    "        option_300 = dropdown.find_element(By.XPATH, './/option[@value=\"300\"]')\n",
    "        option_300.click()\n",
    "\n",
    "        # Wait for table to reload\n",
    "        time.sleep(20)\n",
    "        print(\"‚úÖ Selected 300 rows per page.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to select 300 rows per page: {e}\")\n",
    "select_300_rows_per_page()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7019742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last page number is: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# ‚úÖ Get last page number from <li page-rel=\"lastpage\">\n",
    "def get_last_page_number():\n",
    "    try:\n",
    "        last_page_li = wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, '//li[@page-rel=\"lastpage\"]')\n",
    "        ))\n",
    "        last_page_num = int(last_page_li.get_attribute(\"page-data\"))\n",
    "        print(\"Last page number is:\", last_page_num)\n",
    "        return last_page_num\n",
    "    except Exception as e:\n",
    "        print(\"Failed to get last page number:\", e)\n",
    "        return -1\n",
    "\n",
    "# ‚úÖ Run it to test\n",
    "get_last_page_number()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "700a709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last page number is: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# ‚úÖ Get last page number from <li page-rel=\"lastpage\">\n",
    "def get_last_page_number():\n",
    "    try:\n",
    "        last_page_li = wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, '//li[@page-rel=\"lastpage\"]')\n",
    "        ))\n",
    "        last_page_num = int(last_page_li.get_attribute(\"page-data\"))\n",
    "        print(\"Last page number is:\", last_page_num)\n",
    "        return last_page_num\n",
    "    except Exception as e:\n",
    "        print(\"Failed to get last page number:\", e)\n",
    "        return -1\n",
    "\n",
    "# ‚úÖ Run it to test\n",
    "get_last_page_number()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9fb3447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current page number is: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# ‚úÖ Get current page number from <li class=\"pageItemActive\">\n",
    "def get_current_page_number():\n",
    "    try:\n",
    "        current_li = wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, '//li[contains(@class, \"pageItemActive\")]')\n",
    "        ))\n",
    "        current_page = int(current_li.get_attribute(\"page-data\"))\n",
    "        print(\"Current page number is:\", current_page)\n",
    "        return current_page\n",
    "    except Exception as e:\n",
    "        print(\"Failed to get current page number:\", e)\n",
    "        return -1\n",
    "\n",
    "# ‚úÖ Run it to test\n",
    "get_current_page_number()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5be9aeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ü™Ô∏è Still on page 1, retrying...\n",
      "‚Ü™Ô∏è Still on page 1, retrying...\n",
      "‚úÖ Jumped to last page: 13\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "def get_last_page_number():\n",
    "    try:\n",
    "        last_page_li = wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, '//li[@page-rel=\"lastpage\"]')\n",
    "        ))\n",
    "        return int(last_page_li.get_attribute(\"page-data\"))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to get last page number:\", e)\n",
    "        return -1\n",
    "\n",
    "def get_current_page_number():\n",
    "    try:\n",
    "        current_li = wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, '//li[contains(@class, \"pageItemActive\")]')\n",
    "        ))\n",
    "        return int(current_li.get_attribute(\"page-data\"))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to get current page number:\", e)\n",
    "        return -1\n",
    "\n",
    "def jump_to_last_page():\n",
    "    last_page = get_last_page_number()\n",
    "    if last_page == -1:\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            input_box = wait.until(EC.presence_of_element_located((By.ID, \"whichPage\")))\n",
    "            confirm_btn = driver.find_element(By.ID, \"confirmId\")\n",
    "\n",
    "            input_box.clear()\n",
    "            input_box.send_keys(str(last_page))\n",
    "            confirm_btn.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            current_page = get_current_page_number()\n",
    "            if current_page == last_page:\n",
    "                print(\"‚úÖ Jumped to last page:\", last_page)\n",
    "                return\n",
    "            else:\n",
    "                print(f\"‚Ü™Ô∏è Still on page {current_page}, retrying...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Failed to jump:\", e)\n",
    "            time.sleep(1)\n",
    "\n",
    "# ‚úÖ Run it\n",
    "jump_to_last_page()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce0d5f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:84: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:84: SyntaxWarning: invalid escape sequence '\\['\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20472\\2613232863.py:84: SyntaxWarning: invalid escape sequence '\\['\n",
      "  shop = re.sub(r'\\[.*?\\]', '', tds[1].text.strip())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'import time\\nimport re\\nfrom datetime import datetime\\nfrom selenium.webdriver.common.by import By \\nfrom selenium.webdriver.support.ui import WebDriverWait\\nfrom selenium.webdriver.support import expected_conditions as EC\\n\\n# ‚Üê‚îÄ‚îÄ ADD THIS HERE ‚îÄ‚îÄ‚Üí\\n# Will hold all receipts we‚Äôve already seen\\ntransactions = {}\\n# Initialize WebDriver and go to the target URL first\\n# Example: driver = webdriver.Chrome()\\n\\nwait = WebDriverWait(driver, 15)\\n\\n# ‚úÖ Get current page number\\ndef get_current_page_number():\\n    try:\\n        current_li = wait.until(EC.presence_of_element_located(\\n            (By.XPATH, \\'//li[contains(@class, \"pageItemActive\")]\\')\\n        ))\\n        return int(current_li.get_attribute(\"page-data\"))\\n    except Exception as e:\\n        print(\"Failed to get current page number:\", e)\\n        return -1\\n\\n# ‚úÖ Jump to a specific page (retry until success)\\ndef jump_to_target_page(page_number):\\n    while True:\\n        try:\\n            input_box = wait.until(EC.presence_of_element_located((By.ID, \"whichPage\")))\\n            confirm_btn = driver.find_element(By.ID, \"confirmId\")\\n\\n            input_box.clear()\\n            input_box.send_keys(str(page_number))\\n            confirm_btn.click()\\n            time.sleep(2)\\n\\n            current_page = get_current_page_number()\\n            if current_page == page_number:\\n                print(f\"‚úÖ Jumped to page {page_number}\")\\n                return\\n            else:\\n                print(f\"‚Ü™Ô∏è Still on page {current_page}, retrying page {page_number}...\")\\n\\n        except Exception as e:\\n            print(\"‚ùå Failed to jump:\", e)\\n            time.sleep(1)\\n\\ndef scrape_table(page_number):\\n    print(f\"üìÑ Scraping page {page_number}...\")\\n    rows = wait.until(EC.presence_of_all_elements_located(\\n        (By.XPATH, \\'//table[@class=\"table\" and @hd-freezer-header=\"\"]/tbody/tr\\')\\n    ))\\n\\n    # Pre-scan receipts on this page\\n    raw_receipts = []\\n    for row in rows:\\n        tds = row.find_elements(By.TAG_NAME, \"td\")\\n        if not tds or tds[0].text.strip() == \"ÈááÈõÜÂâçÁ´Ø\":\\n            continue\\n        raw_receipts.append(tds[4].text.strip())\\n\\n    # If there are no rows or they\\'re all duplicates, bail out\\n    if not raw_receipts or all(r in transactions for r in raw_receipts):\\n        print(f\"‚ö†Ô∏è No new receipts on page {page_number}\")\\n        return False\\n\\n    # Otherwise process each row, skipping individual duplicates\\n    new_found = False\\n    for row in rows:\\n        tds = row.find_elements(By.TAG_NAME, \"td\")\\n        if not tds or tds[0].text.strip() == \"ÈááÈõÜÂâçÁ´Ø\":\\n            continue\\n\\n        raw_receipt = tds[4].text.strip()\\n\\n        # ‚Üê‚îÄ‚îÄ DUPLICATE CHECK: skip if already scraped ‚îÄ‚îÄ‚Üí\\n        if raw_receipt in transactions:\\n            print(f\"‚ö†Ô∏è Skipping duplicate receipt {raw_receipt}\")\\n            continue\\n\\n        # ‚Ä¶ your cleaning/parsing ‚Ä¶\\n        shop = re.sub(r\\'\\\\[.*?\\\\]\\', \\'\\', tds[1].text.strip())\\n        shop = \\'\\'.join(re.findall(r\\'[‰∏Ä-Èøø]+\\', shop))\\n\\n        settle_dt  = datetime.strptime(tds[2].text.strip(), \"%Y-%m-%d\").date()\\n        trans_time = datetime.strptime(tds[12].text.strip(), \"%Y-%m-%d %H:%M:%S\")\\n        amount     = float(tds[5].text.strip().replace(\",\", \"\"))\\n\\n        # ‚Üê‚îÄ‚îÄ STORE the new receipt ‚îÄ‚îÄ‚Üí\\n        transactions[raw_receipt] = {\\n            \"shop\":       shop,\\n            \"settle_dt\":  settle_dt,\\n            \"trans_time\": trans_time,\\n            \"amount\":     amount\\n        }\\n\\n        # ‚Üê‚îÄ‚îÄ PRINT new receipt ‚îÄ‚îÄ‚Üí\\n        print(f\"‚úîÔ∏è Saved Receipt: {raw_receipt} | Shop: {shop} | \"\\n              f\"Date: {settle_dt} | Time: {trans_time.time()} | \"\\n              f\"Amount: {amount:.2f}\")\\n\\n        new_found = True\\n\\n    return new_found\\n\\n\\n\\n# ‚úÖ Main loop: scrape current page, then go backward\\ndef scrape_backwards_from_current():\\n    target_page = get_current_page_number()\\n\\n    if target_page == -1:\\n        print(\"‚ùå Cannot detect starting page.\")\\n        return\\n\\n    while target_page >= 1:\\n        print(f\"‚û°Ô∏è Target page to scrape: {target_page}\")\\n        if target_page != get_current_page_number():\\n            jump_to_target_page(target_page)\\n        scrape_table(target_page)\\n        target_page -= 1\\n\\n    print(\"‚úÖ Finished scraping all pages.\")\\n\\n# ‚úÖ Run\\ndef get_last_page_number():\\n    try:\\n        li = wait.until(EC.presence_of_element_located(\\n            (By.XPATH, \\'//li[@page-rel=\"lastpage\"]\\')))\\n        return int(li.get_attribute(\"page-data\"))\\n    except Exception as e:\\n        print(\"Failed to get last page number:\", e)\\n        return -1\\n\\n# ---------- NEW real-time loop ----------\\n# ---------- NEW real-time loop ----------\\ndef realtime_scrape_loop(refresh_seconds=60):\\n    while True:\\n        print(\"üîÑ Refreshing page...\")\\n        driver.refresh()\\n        time.sleep(3)  # let everything settle\\n\\n        cycle_new = False\\n        page = 1\\n\\n        # Scrape page 1, 2, 3‚Ä¶ until scrape_table returns False\\n        while True:\\n            got_new = scrape_table(page)\\n            if got_new:\\n                cycle_new = True\\n                page += 1\\n            else:\\n                break\\n\\n        if cycle_new:\\n            print(\"üéâ New receipts found and scraped this cycle.\")\\n        else:\\n            print(\"‚ö†Ô∏è No new receipts this cycle.\")\\n\\n        print(f\"‚è≥ Sleeping for {refresh_seconds} seconds‚Ä¶\\n\")\\n        time.sleep(refresh_seconds)\\n\\n\\nscrape_backwards_from_current()\\nrealtime_scrape_loop(refresh_seconds=60)  # Adjust as needed\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# ‚Üê‚îÄ‚îÄ ADD THIS HERE ‚îÄ‚îÄ‚Üí\n",
    "# Will hold all receipts we‚Äôve already seen\n",
    "transactions = {}\n",
    "# Initialize WebDriver and go to the target URL first\n",
    "# Example: driver = webdriver.Chrome()\n",
    "\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# ‚úÖ Get current page number\n",
    "def get_current_page_number():\n",
    "    try:\n",
    "        current_li = wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, '//li[contains(@class, \"pageItemActive\")]')\n",
    "        ))\n",
    "        return int(current_li.get_attribute(\"page-data\"))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to get current page number:\", e)\n",
    "        return -1\n",
    "\n",
    "# ‚úÖ Jump to a specific page (retry until success)\n",
    "def jump_to_target_page(page_number):\n",
    "    while True:\n",
    "        try:\n",
    "            input_box = wait.until(EC.presence_of_element_located((By.ID, \"whichPage\")))\n",
    "            confirm_btn = driver.find_element(By.ID, \"confirmId\")\n",
    "\n",
    "            input_box.clear()\n",
    "            input_box.send_keys(str(page_number))\n",
    "            confirm_btn.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            current_page = get_current_page_number()\n",
    "            if current_page == page_number:\n",
    "                print(f\"‚úÖ Jumped to page {page_number}\")\n",
    "                return\n",
    "            else:\n",
    "                print(f\"‚Ü™Ô∏è Still on page {current_page}, retrying page {page_number}...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå Failed to jump:\", e)\n",
    "            time.sleep(1)\n",
    "\n",
    "def scrape_table(page_number):\n",
    "    print(f\"üìÑ Scraping page {page_number}...\")\n",
    "    rows = wait.until(EC.presence_of_all_elements_located(\n",
    "        (By.XPATH, '//table[@class=\"table\" and @hd-freezer-header=\"\"]/tbody/tr')\n",
    "    ))\n",
    "\n",
    "    # Pre-scan receipts on this page\n",
    "    raw_receipts = []\n",
    "    for row in rows:\n",
    "        tds = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if not tds or tds[0].text.strip() == \"ÈááÈõÜÂâçÁ´Ø\":\n",
    "            continue\n",
    "        raw_receipts.append(tds[4].text.strip())\n",
    "\n",
    "    # If there are no rows or they're all duplicates, bail out\n",
    "    if not raw_receipts or all(r in transactions for r in raw_receipts):\n",
    "        print(f\"‚ö†Ô∏è No new receipts on page {page_number}\")\n",
    "        return False\n",
    "\n",
    "    # Otherwise process each row, skipping individual duplicates\n",
    "    new_found = False\n",
    "    for row in rows:\n",
    "        tds = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if not tds or tds[0].text.strip() == \"ÈááÈõÜÂâçÁ´Ø\":\n",
    "            continue\n",
    "\n",
    "        raw_receipt = tds[4].text.strip()\n",
    "\n",
    "        # ‚Üê‚îÄ‚îÄ DUPLICATE CHECK: skip if already scraped ‚îÄ‚îÄ‚Üí\n",
    "        if raw_receipt in transactions:\n",
    "            print(f\"‚ö†Ô∏è Skipping duplicate receipt {raw_receipt}\")\n",
    "            continue\n",
    "\n",
    "        # ‚Ä¶ your cleaning/parsing ‚Ä¶\n",
    "        shop = re.sub(r'\\[.*?\\]', '', tds[1].text.strip())\n",
    "        shop = ''.join(re.findall(r'[\\u4e00-\\u9fff]+', shop))\n",
    "\n",
    "        settle_dt  = datetime.strptime(tds[2].text.strip(), \"%Y-%m-%d\").date()\n",
    "        trans_time = datetime.strptime(tds[12].text.strip(), \"%Y-%m-%d %H:%M:%S\")\n",
    "        amount     = float(tds[5].text.strip().replace(\",\", \"\"))\n",
    "\n",
    "        # ‚Üê‚îÄ‚îÄ STORE the new receipt ‚îÄ‚îÄ‚Üí\n",
    "        transactions[raw_receipt] = {\n",
    "            \"shop\":       shop,\n",
    "            \"settle_dt\":  settle_dt,\n",
    "            \"trans_time\": trans_time,\n",
    "            \"amount\":     amount\n",
    "        }\n",
    "\n",
    "        # ‚Üê‚îÄ‚îÄ PRINT new receipt ‚îÄ‚îÄ‚Üí\n",
    "        print(f\"‚úîÔ∏è Saved Receipt: {raw_receipt} | Shop: {shop} | \"\n",
    "              f\"Date: {settle_dt} | Time: {trans_time.time()} | \"\n",
    "              f\"Amount: {amount:.2f}\")\n",
    "\n",
    "        new_found = True\n",
    "\n",
    "    return new_found\n",
    "\n",
    "\n",
    "\n",
    "# ‚úÖ Main loop: scrape current page, then go backward\n",
    "def scrape_backwards_from_current():\n",
    "    target_page = get_current_page_number()\n",
    "\n",
    "    if target_page == -1:\n",
    "        print(\"‚ùå Cannot detect starting page.\")\n",
    "        return\n",
    "\n",
    "    while target_page >= 1:\n",
    "        print(f\"‚û°Ô∏è Target page to scrape: {target_page}\")\n",
    "        if target_page != get_current_page_number():\n",
    "            jump_to_target_page(target_page)\n",
    "        scrape_table(target_page)\n",
    "        target_page -= 1\n",
    "\n",
    "    print(\"‚úÖ Finished scraping all pages.\")\n",
    "\n",
    "# ‚úÖ Run\n",
    "def get_last_page_number():\n",
    "    try:\n",
    "        li = wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, '//li[@page-rel=\"lastpage\"]')))\n",
    "        return int(li.get_attribute(\"page-data\"))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to get last page number:\", e)\n",
    "        return -1\n",
    "\n",
    "# ---------- NEW real-time loop ----------\n",
    "# ---------- NEW real-time loop ----------\n",
    "def realtime_scrape_loop(refresh_seconds=60):\n",
    "    while True:\n",
    "        print(\"üîÑ Refreshing page...\")\n",
    "        driver.refresh()\n",
    "        time.sleep(3)  # let everything settle\n",
    "\n",
    "        cycle_new = False\n",
    "        page = 1\n",
    "\n",
    "        # Scrape page 1, 2, 3‚Ä¶ until scrape_table returns False\n",
    "        while True:\n",
    "            got_new = scrape_table(page)\n",
    "            if got_new:\n",
    "                cycle_new = True\n",
    "                page += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if cycle_new:\n",
    "            print(\"üéâ New receipts found and scraped this cycle.\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No new receipts this cycle.\")\n",
    "\n",
    "        print(f\"‚è≥ Sleeping for {refresh_seconds} seconds‚Ä¶\\n\")\n",
    "        time.sleep(refresh_seconds)\n",
    "\n",
    "\n",
    "scrape_backwards_from_current()\n",
    "realtime_scrape_loop(refresh_seconds=60)  # Adjust as needed\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3e3c569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ [HISTORY] Scraping page 1‚Ä¶\n",
      "‚úîÔ∏è [HISTORY] Saved 25071498014031911229 @ 2025-07-14 11:03:41\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#60 @ 2025-07-14 11:03:37\n",
      "‚úîÔ∏è [HISTORY] Saved 8093596042246605288 @ 2025-07-14 11:03:43\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#321194352 @ 2025-07-14 11:03:32\n",
      "‚úîÔ∏è [HISTORY] Saved 8062656042277549321 @ 2025-07-14 11:03:33\n",
      "‚úîÔ∏è [HISTORY] Saved 8021636042272319988 @ 2025-07-14 11:03:10\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#321194014 @ 2025-07-14 11:02:25\n",
      "‚úîÔ∏è [HISTORY] Saved D90037149531740798976 @ 2025-07-14 11:03:20\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#59 @ 2025-07-14 11:02:14\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#58 @ 2025-07-14 11:02:05\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#24 @ 2025-07-14 11:02:06\n",
      "‚úîÔ∏è [HISTORY] Saved 8078270208455485914 @ 2025-07-14 11:02:02\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#2025-07-1411:01:36 @ 2025-07-14 11:01:44\n",
      "‚úîÔ∏è [HISTORY] Saved 8098916042268324279 @ 2025-07-14 11:01:03\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#57 @ 2025-07-14 11:00:56\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#56 @ 2025-07-14 11:00:39\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#55 @ 2025-07-14 11:00:22\n",
      "‚úîÔ∏è [HISTORY] Saved 202507140002 @ 2025-07-14 11:00:17\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 202507140002\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#7 @ 2025-07-14 10:59:52\n",
      "‚úîÔ∏è [HISTORY] Saved 8066410208414157307 @ 2025-07-14 10:59:40\n",
      "‚úîÔ∏è [HISTORY] Saved 8026310208447594791 @ 2025-07-14 10:59:19\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#54 @ 2025-07-14 10:59:09\n",
      "‚úîÔ∏è [HISTORY] Saved 326131715527 @ 2025-07-14 10:59:00\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#2025-07-1410:58:42 @ 2025-07-14 10:58:51\n",
      "‚úîÔ∏è [HISTORY] Saved 8012546042264242669 @ 2025-07-14 10:58:18\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#23 @ 2025-07-14 10:57:56\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#53 @ 2025-07-14 10:57:37\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#22 @ 2025-07-14 10:57:38\n",
      "‚úîÔ∏è [HISTORY] Saved 8091736042268185976 @ 2025-07-14 10:56:37\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#22092 @ 2025-07-14 10:56:12\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#22092\n",
      "‚úîÔ∏è [HISTORY] Saved P018LS-2025-07-14-004 @ 2025-07-14 10:56:10\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#52 @ 2025-07-14 10:56:08\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#51 @ 2025-07-14 10:56:08\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#18621716272 @ 2025-07-14 10:55:57\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#18621716272\n",
      "‚úîÔ∏è [HISTORY] Saved 8051100208414551471 @ 2025-07-14 10:55:42\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#50 @ 2025-07-14 10:55:29\n",
      "‚úîÔ∏è [HISTORY] Saved 25071498016551810230 @ 2025-07-14 10:55:25\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#21 @ 2025-07-14 10:55:22\n",
      "‚úîÔ∏è [HISTORY] Saved 250713#1 @ 2025-07-14 10:55:10\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#49 @ 2025-07-14 10:55:09\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#48 @ 2025-07-14 10:55:01\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#47 @ 2025-07-14 10:54:49\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#46 @ 2025-07-14 10:54:37\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#45 @ 2025-07-14 10:54:20\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#2025-07-1410:54:11 @ 2025-07-14 10:54:20\n",
      "‚úîÔ∏è [HISTORY] Saved 8026220208355804545 @ 2025-07-14 10:54:11\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#43 @ 2025-07-14 10:54:04\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#42 @ 2025-07-14 10:54:03\n",
      "‚úîÔ∏è [HISTORY] Saved 8042546042259666284 @ 2025-07-14 10:54:03\n",
      "‚úîÔ∏è [HISTORY] Saved D90037147361657958400 @ 2025-07-14 10:54:43\n",
      "‚úîÔ∏è [HISTORY] Saved 8052140208480346518 @ 2025-07-14 10:53:22\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#35 @ 2025-07-14 10:53:15\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#41 @ 2025-07-14 10:53:15\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#40 @ 2025-07-14 10:53:07\n",
      "‚úîÔ∏è [HISTORY] Saved 8064110208447463854 @ 2025-07-14 10:53:09\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#39 @ 2025-07-14 10:52:45\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#38 @ 2025-07-14 10:52:32\n",
      "‚úîÔ∏è [HISTORY] Saved 25071498012520910851 @ 2025-07-14 10:52:24\n",
      "‚úîÔ∏è [HISTORY] Saved P018LS-2025-07-14-003 @ 2025-07-14 10:52:22\n",
      "‚úîÔ∏è [HISTORY] Saved 8097020208446568866 @ 2025-07-14 10:52:27\n",
      "‚úîÔ∏è [HISTORY] Saved 2001685451695654552 @ 2025-07-14 10:56:43\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#37 @ 2025-07-14 10:51:59\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#20 @ 2025-07-14 10:51:37\n",
      "‚úîÔ∏è [HISTORY] Saved 8002816042233467150 @ 2025-07-14 10:51:42\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#36 @ 2025-07-14 10:51:20\n",
      "‚úîÔ∏è [HISTORY] Saved 118878342507130040 @ 2025-07-14 10:51:05\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#35\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#19 @ 2025-07-14 10:50:55\n",
      "‚úîÔ∏è [HISTORY] Saved 250713#2 @ 2025-07-14 10:50:52\n",
      "‚úîÔ∏è [HISTORY] Saved 250713#29 @ 2025-07-14 10:50:48\n",
      "‚úîÔ∏è [HISTORY] Saved 8084836042267411928 @ 2025-07-14 10:50:48\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#34 @ 2025-07-14 10:50:43\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#33 @ 2025-07-14 10:50:05\n",
      "‚úîÔ∏è [HISTORY] Saved 2001685440274544221 @ 2025-07-14 10:54:00\n",
      "‚úîÔ∏è [HISTORY] Saved 8039400208479451549 @ 2025-07-14 10:50:04\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#18 @ 2025-07-14 10:49:43\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#32 @ 2025-07-14 10:49:26\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#16 @ 2025-07-14 10:49:13\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#16\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#31 @ 2025-07-14 10:49:12\n",
      "‚úîÔ∏è [HISTORY] Saved 2001685441710505625 @ 2025-07-14 10:52:45\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#31\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#17 @ 2025-07-14 10:49:12\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#17\n",
      "‚úîÔ∏è [HISTORY] Saved 8094686042266671570 @ 2025-07-14 10:49:00\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#30 @ 2025-07-14 10:48:54\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#30\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#16\n",
      "‚úîÔ∏è [HISTORY] Saved 37003250714104333672 @ 2025-07-14 10:48:18\n",
      "‚úîÔ∏è [HISTORY] Saved 8011676042254908760 @ 2025-07-14 10:48:16\n",
      "‚úîÔ∏è [HISTORY] Saved 136942202507140002 @ 2025-07-14 10:47:43\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#15 @ 2025-07-14 10:48:05\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#14 @ 2025-07-14 10:47:43\n",
      "‚úîÔ∏è [HISTORY] Saved 8091460208437304703 @ 2025-07-14 10:47:32\n",
      "‚úîÔ∏è [HISTORY] Saved 8006190208345104781 @ 2025-07-14 10:47:01\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#13 @ 2025-07-14 10:46:51\n",
      "‚úîÔ∏è [HISTORY] Saved P018LS-2025-07-14-002 @ 2025-07-14 10:45:51\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#29 @ 2025-07-14 10:45:48\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#28 @ 2025-07-14 10:45:36\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#12 @ 2025-07-14 10:45:14\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#15\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#4 @ 2025-07-14 10:44:18\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#5 @ 2025-07-14 10:44:16\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#2 @ 2025-07-14 10:44:09\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#3 @ 2025-07-14 10:44:04\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#1 @ 2025-07-14 10:43:57\n",
      "‚úîÔ∏è [HISTORY] Saved D90037144883898064896 @ 2025-07-14 10:44:52\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#11 @ 2025-07-14 10:43:54\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250713#29\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250713#29\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#10 @ 2025-07-14 10:43:17\n",
      "‚úîÔ∏è [HISTORY] Saved 318990844287 @ 2025-07-14 10:43:10\n",
      "‚úîÔ∏è [HISTORY] Saved 136942202507140001 @ 2025-07-14 10:42:13\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#27 @ 2025-07-14 10:42:25\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#9 @ 2025-07-14 10:42:18\n",
      "‚úîÔ∏è [HISTORY] Saved 8090220208471311821 @ 2025-07-14 10:41:39\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#26 @ 2025-07-14 10:41:16\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#25 @ 2025-07-14 10:41:08\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#24\n",
      "‚úîÔ∏è [HISTORY] Saved 8073766042219768305 @ 2025-07-14 10:40:58\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#8 @ 2025-07-14 10:40:49\n",
      "‚úîÔ∏è [HISTORY] Saved 8043460208474611094 @ 2025-07-14 10:40:37\n",
      "‚úîÔ∏è [HISTORY] Saved 8033906042223921499 @ 2025-07-14 10:39:26\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#502 @ 2025-07-14 10:39:10\n",
      "‚úîÔ∏è [HISTORY] Saved 8029190208406541808 @ 2025-07-14 10:38:57\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#23\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#7\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#22\n",
      "‚úîÔ∏è [HISTORY] Saved 8040596042222965144 @ 2025-07-14 10:37:34\n",
      "‚úîÔ∏è [HISTORY] Saved 8095450208467546728 @ 2025-07-14 10:39:11\n",
      "‚úîÔ∏è [HISTORY] Saved 8032130208462833053 @ 2025-07-14 10:35:45\n",
      "‚úîÔ∏è [HISTORY] Saved 8010916042221938110 @ 2025-07-14 10:35:43\n",
      "‚úîÔ∏è [HISTORY] Saved 326158238955 @ 2025-07-14 10:35:33\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#10\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#6 @ 2025-07-14 10:35:06\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#7\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#14\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#13\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#501 @ 2025-07-14 10:34:57\n",
      "‚úîÔ∏è [HISTORY] Saved 8059580208455752985 @ 2025-07-14 10:35:51\n",
      "‚úîÔ∏è [HISTORY] Saved 8079886042244444662 @ 2025-07-14 10:33:14\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#21\n",
      "‚úîÔ∏è [HISTORY] Saved 2001685450161190425 @ 2025-07-14 10:34:18\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#20\n",
      "‚úîÔ∏è [HISTORY] Saved 8035230208432607493 @ 2025-07-14 10:32:19\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#19\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#2\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#4\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#6\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#18\n",
      "‚úîÔ∏è [HISTORY] Saved 8062030208433042722 @ 2025-07-14 10:29:23\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#17\n",
      "‚úîÔ∏è [HISTORY] Saved 8044150208454498055 @ 2025-07-14 10:29:32\n",
      "‚úîÔ∏è [HISTORY] Saved D90037140924571 869184 @ 2025-07-14 10:29:17\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#16\n",
      "‚úîÔ∏è [HISTORY] Saved 8068676042218075397 @ 2025-07-14 10:27:42\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#2025-07-1410:27:14 @ 2025-07-14 10:27:22\n",
      "‚úîÔ∏è [HISTORY] Saved 8050926042222500272 @ 2025-07-14 10:25:30\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#12\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#11\n",
      "‚úîÔ∏è [HISTORY] Saved 2501685421519757955 @ 2025-07-14 10:25:02\n",
      "‚úîÔ∏è [HISTORY] Saved 8036170208338955629 @ 2025-07-14 10:24:36\n",
      "‚úîÔ∏è [HISTORY] Saved 202507140001 @ 2025-07-14 10:23:27\n",
      "‚úîÔ∏è [HISTORY] Saved 8052470208391996841 @ 2025-07-14 10:23:15\n",
      "‚úîÔ∏è [HISTORY] Saved 8006866042252784920 @ 2025-07-14 10:23:05\n",
      "‚úîÔ∏è [HISTORY] Saved D90037139587398037504 @ 2025-07-14 10:23:48\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#2\n",
      "‚úîÔ∏è [HISTORY] Saved FXP5370250714010001 @ 2025-07-14 10:21:46\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt FXP5370250714010001\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 202507140001\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 202507140001\n",
      "‚úîÔ∏è [HISTORY] Saved 8042200208464700715 @ 2025-07-14 10:20:51\n",
      "‚úîÔ∏è [HISTORY] Saved 102507141000771209600001 @ 2025-07-14 10:20:13\n",
      "‚úîÔ∏è [HISTORY] Saved 1256942223651157 @ 2025-07-14 10:19:37\n",
      "‚úîÔ∏è [HISTORY] Saved 8040696042214985039 @ 2025-07-14 10:19:40\n",
      "‚úîÔ∏è [HISTORY] Saved D90037138723732422656 @ 2025-07-14 10:20:22\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#9\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#1\n",
      "‚úîÔ∏è [HISTORY] Saved 202507141017238000001 @ 2025-07-14 10:18:20\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#321191010 @ 2025-07-14 10:16:20\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#321189414 @ 2025-07-14 10:15:22\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#3\n",
      "‚úîÔ∏è [HISTORY] Saved D90037137544851709952 @ 2025-07-14 10:17:17\n",
      "‚úîÔ∏è [HISTORY] Saved D90037137590884184064 @ 2025-07-14 10:17:19\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt D90037137544851709952\n",
      "‚úîÔ∏è [HISTORY] Saved D90037136178842382336 @ 2025-07-14 10:17:16\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt D90037136178842382336\n",
      "‚úîÔ∏è [HISTORY] Saved P018LS-2025-07-14-001 @ 2025-07-14 10:10:10\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt D90037136178842382336\n",
      "‚úîÔ∏è [HISTORY] Saved D90037136011728728064 @ 2025-07-14 10:17:14\n",
      "‚úîÔ∏è [HISTORY] Saved 8064856042210541908 @ 2025-07-14 10:09:21\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#10002 @ 2025-07-14 10:09:08\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt D90037136011728728064\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#8\n",
      "‚úîÔ∏è [HISTORY] Saved 250714100519011424 @ 2025-07-14 10:06:34\n",
      "‚úîÔ∏è [HISTORY] Saved 8022160208453009819 @ 2025-07-14 10:06:19\n",
      "‚úîÔ∏è [HISTORY] Saved 8021906042212103520 @ 2025-07-14 10:05:37\n",
      "‚úîÔ∏è [HISTORY] Saved 250714093448011423 @ 2025-07-14 10:05:28\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#10001 @ 2025-07-14 10:05:07\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#5\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 250714#1\n",
      "‚úîÔ∏è [HISTORY] Saved 8069586042214076809 @ 2025-07-14 10:03:39\n",
      "‚úîÔ∏è [HISTORY] Saved 81568912507130077 @ 2025-07-14 10:00:41\n",
      "‚úîÔ∏è [HISTORY] Saved D90037123166299525120 @ 2025-07-14 10:17:13\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#2025-07-1409:58:58 @ 2025-07-14 09:59:09\n",
      "‚úîÔ∏è [HISTORY] Saved 50250712017 @ 2025-07-14 09:58:32\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 50250712017\n",
      "‚úîÔ∏è [HISTORY] Saved 250714#321189110 @ 2025-07-14 09:57:27\n",
      "‚úîÔ∏è [HISTORY] Saved 8001706042203255203 @ 2025-07-14 09:54:30\n",
      "‚úîÔ∏è [HISTORY] Saved 319034629040 @ 2025-07-14 09:50:48\n",
      "‚úîÔ∏è [HISTORY] Saved ZDO625070078 @ 2025-07-14 09:50:30\n",
      "‚úîÔ∏è [HISTORY] Saved ZDO625070077 @ 2025-07-14 09:50:05\n",
      "‚úîÔ∏è [HISTORY] Saved 250713#21 @ 2025-07-14 09:45:07\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt D90037123166299525120\n",
      "‚úîÔ∏è [HISTORY] Saved D90037122695715287040 @ 2025-07-14 10:17:10\n",
      "‚úîÔ∏è [HISTORY] Saved D90037118869981573120 @ 2025-07-14 10:17:08\n",
      "‚úîÔ∏è [HISTORY] Saved 8098050208419398917 @ 2025-07-14 09:44:33\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt D90037118869981573120\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt D90037118869981573120\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 50250712017\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt 50250712017\n",
      "‚úîÔ∏è [HISTORY] Saved 8098120208324756898 @ 2025-07-14 09:39:29\n",
      "‚ö†Ô∏è [HISTORY] Skipping duplicate receipt D90037122695715287040\n",
      "‚úîÔ∏è [HISTORY] Saved 8010916042196864318 @ 2025-07-14 09:38:38\n",
      "‚úîÔ∏è [HISTORY] Saved D00175241429480070071 @ 2025-07-14 10:17:00\n",
      "‚úîÔ∏è [HISTORY] Saved D00175241114332296896 @ 2025-07-14 10:16:57\n",
      "‚úîÔ∏è [HISTORY] Saved D00175241118831373160 @ 2025-07-14 10:16:59\n",
      "‚úîÔ∏è [HISTORY] Saved D00175241147369315456 @ 2025-07-14 10:17:03\n",
      "‚úîÔ∏è [HISTORY] Saved D90036932348314091520 @ 2025-07-14 10:16:43\n",
      "‚úîÔ∏è [HISTORY] Saved D9003693537682801 4592 @ 2025-07-14 10:16:53\n",
      "‚úîÔ∏è [HISTORY] Saved D00175241076833839709 @ 2025-07-14 10:16:47\n",
      "‚úîÔ∏è [HISTORY] Saved D900369336862841 651 20 @ 2025-07-14 10:16:48\n",
      "‚úîÔ∏è [HISTORY] Saved D90036933506051 035136 @ 2025-07-14 10:16:46\n",
      "‚úîÔ∏è [HISTORY] Saved D90036932043677421 568 @ 2025-07-14 10:16:45\n",
      "‚úîÔ∏è [HISTORY] Saved D90036932030184464384 @ 2025-07-14 10:16:42\n",
      "‚úîÔ∏è [HISTORY] Saved D9003692804739920691 2 @ 2025-07-14 10:16:38\n",
      "‚úîÔ∏è [HISTORY] Saved D90036927006003621 888 @ 2025-07-14 10:16:35\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240854034063174 @ 2025-07-14 10:16:28\n",
      "‚úîÔ∏è [HISTORY] Saved D90036924610620162048 @ 2025-07-14 10:16:32\n",
      "‚úîÔ∏è [HISTORY] Saved D00175241000623928698 @ 2025-07-14 10:16:40\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240943065522940 @ 2025-07-14 10:16:37\n",
      "‚úîÔ∏è [HISTORY] Saved D900369251 61034203136 @ 2025-07-14 10:16:33\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240860913485220 @ 2025-07-14 10:16:31\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240832770450731 @ 2025-07-14 10:16:24\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240837821879026 @ 2025-07-14 10:16:23\n",
      "‚úîÔ∏è [HISTORY] Saved D90036924321829699584 @ 2025-07-14 10:16:26\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240757420788170 @ 2025-07-14 10:16:18\n",
      "‚úîÔ∏è [HISTORY] Saved D90036922551782887424 @ 2025-07-14 10:16:20\n",
      "‚úîÔ∏è [HISTORY] Saved D90036919137305063424 @ 2025-07-14 10:16:13\n",
      "‚úîÔ∏è [HISTORY] Saved D90036919678407757824 @ 2025-07-14 10:16:15\n",
      "‚úîÔ∏è [HISTORY] Saved D90036921763681 591296 @ 2025-07-14 10:16:16\n",
      "‚úîÔ∏è [HISTORY] Saved D001 75240803397147302 @ 2025-07-14 10:16:19\n",
      "‚úîÔ∏è [HISTORY] Saved D90036914610438737920 @ 2025-07-14 10:16:03\n",
      "‚úîÔ∏è [HISTORY] Saved D90036916884338552832 @ 2025-07-14 10:16:11\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240635761704107 @ 2025-07-14 10:16:05\n",
      "‚úîÔ∏è [HISTORY] Saved D90036917004949950464 @ 2025-07-14 10:16:10\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240654478981722 @ 2025-07-14 10:16:08\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240583450506090 @ 2025-07-14 10:15:59\n",
      "‚úîÔ∏è [HISTORY] Saved D90036915257997467648 @ 2025-07-14 10:16:02\n",
      "‚úîÔ∏è [HISTORY] Saved D90036912664185188352 @ 2025-07-14 10:15:57\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240399965484984 @ 2025-07-14 10:15:44\n",
      "‚úîÔ∏è [HISTORY] Saved D90036908877915770880 @ 2025-07-14 10:15:55\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240475316877012 @ 2025-07-14 10:15:52\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240429952893885 @ 2025-07-14 10:15:52\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240408903048129 @ 2025-07-14 10:15:48\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240434277442137 @ 2025-07-14 10:15:50\n",
      "‚úîÔ∏è [HISTORY] Saved D900369101953045381 12 @ 2025-07-14 10:15:55\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240341940939344 @ 2025-07-14 10:15:32\n",
      "‚úîÔ∏è [HISTORY] Saved D90036903201885687808 @ 2025-07-14 10:15:34\n",
      "‚úîÔ∏è [HISTORY] Saved D90036905035622809600 @ 2025-07-14 10:15:39\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240369956955948 @ 2025-07-14 10:15:35\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240397971603707 @ 2025-07-14 10:15:44\n",
      "‚úîÔ∏è [HISTORY] Saved D9003690540936061 3376 @ 2025-07-14 10:15:42\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240393039466066 @ 2025-07-14 10:15:41\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240360336032430 @ 2025-07-14 10:15:38\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240284524892406 @ 2025-07-14 10:15:28\n",
      "‚úîÔ∏è [HISTORY] Saved D90036896567725899776 @ 2025-07-14 10:15:20\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240152052321840 @ 2025-07-14 10:15:17\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240306981743940 @ 2025-07-14 10:15:29\n",
      "‚úîÔ∏è [HISTORY] Saved D9003689693278544691 2 @ 2025-07-14 10:15:22\n",
      "‚úîÔ∏è [HISTORY] Saved D90036900163108417536 @ 2025-07-14 10:15:26\n",
      "‚úîÔ∏è [HISTORY] Saved D90036897132253962240 @ 2025-07-14 10:15:27\n",
      "‚úîÔ∏è [HISTORY] Saved D90036890293839532032 @ 2025-07-14 10:15:06\n",
      "‚úîÔ∏è [HISTORY] Saved D9003689246685821 7472 @ 2025-07-14 10:15:10\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240096678365051 @ 2025-07-14 10:15:13\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240130960292894 @ 2025-07-14 10:15:16\n",
      "‚úîÔ∏è [HISTORY] Saved D001752400575336851 13 @ 2025-07-14 10:15:04\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240061553074650 @ 2025-07-14 10:15:07\n",
      "‚úîÔ∏è [HISTORY] Saved D0017524008589091 6847 @ 2025-07-14 10:15:12\n",
      "‚úîÔ∏è [HISTORY] Saved D00175240067501421254 @ 2025-07-14 10:15:10\n",
      "‚úîÔ∏è [HISTORY] Saved D900368866503443701 76 @ 2025-07-14 10:14:52\n",
      "‚úîÔ∏è [HISTORY] Saved D00175239963819798559 @ 2025-07-14 10:14:55\n",
      "‚úîÔ∏è [HISTORY] Saved D900368881 59589175296 @ 2025-07-14 10:15:00\n",
      "‚úîÔ∏è [HISTORY] Saved D90036887453242961 920 @ 2025-07-14 10:14:58\n",
      "‚úîÔ∏è [HISTORY] Saved D0017524002689481 6366 @ 2025-07-14 10:15:02\n",
      "‚úîÔ∏è [HISTORY] Saved D90036885359412899840 @ 2025-07-14 10:14:53\n",
      "‚úîÔ∏è [HISTORY] Saved D00175239974415406466 @ 2025-07-14 10:15:01\n",
      "‚úÖ Finished history scrape.\n",
      "üîñ last_time set to 2025-07-14 11:03:43\n",
      "üìÑ [REALTIME] Scraping page 1‚Ä¶\n",
      "‚úîÔ∏è [REALTIME] New receipt 8004946042243901759 | 2025-07-14 11:04:33 | Ëæ£Â†ÇËµ£ | 27.90\n",
      "‚úîÔ∏è [REALTIME] New receipt 250714#10003 | 2025-07-14 11:04:13 |  | 9.90\n",
      "üìÑ [REALTIME] Scraping page 2‚Ä¶\n",
      "üéâ New receipts!\n",
      "üìÑ [REALTIME] Scraping page 1‚Ä¶\n",
      "‚úîÔ∏è [REALTIME] New receipt 0009000925071400001 | 2025-07-14 11:05:58 | Ëå∂‰πêÂ™û | 68.00\n",
      "‚úîÔ∏è [REALTIME] New receipt 250713#7 | 2025-07-14 11:05:55 | Á±≥ÊùëÊãåÈ•≠Â†ÇÈ£ü | 0.00\n",
      "‚úîÔ∏è [REALTIME] New receipt 318990000734 | 2025-07-14 11:05:45 | ÁªøÂ°îÂ∏ÇÈõÜ | 29.21\n",
      "‚úîÔ∏è [REALTIME] New receipt 326151962082 | 2025-07-14 11:05:34 | ÁªøÂ°îÂ∏ÇÈõÜ | 49.00\n",
      "‚úîÔ∏è [REALTIME] New receipt 250714#Êó•. | 2025-07-14 11:05:29 | ÂçéÊ∞èÂ§ßËçØÊàø | 88.50\n",
      "‚úîÔ∏è [REALTIME] New receipt 250714#63 | 2025-07-14 11:05:23 | Á±≥ÊùëÊãåÈ•≠Â†ÇÈ£ü | 13.40\n",
      "‚úîÔ∏è [REALTIME] New receipt 250714#62 | 2025-07-14 11:05:22 | Á±≥ÊùëÊãåÈ•≠Â†ÇÈ£ü | 19.20\n",
      "‚úîÔ∏è [REALTIME] New receipt 250714#61 | 2025-07-14 11:04:50 | Á±≥ÊùëÊãåÈ•≠Â†ÇÈ£ü | 20.20\n",
      "üìÑ [REALTIME] Scraping page 2‚Ä¶\n",
      "üéâ New receipts!\n",
      "üìÑ [REALTIME] Scraping page 1‚Ä¶\n",
      "‚úîÔ∏è [REALTIME] New receipt 326148962080 | 2025-07-14 11:07:16 | ÁªøÂ°îÂ∏ÇÈõÜ | 41.00\n",
      "‚úîÔ∏è [REALTIME] New receipt D900371 50474343231488 | 2025-07-14 11:07:06 | ÈπøËßíÂ∑∑ | 13.00\n",
      "‚úîÔ∏è [REALTIME] New receipt D90037150417837707264 | 2025-07-14 11:07:03 | ÈπøËßíÂ∑∑ | 6.90\n",
      "‚úîÔ∏è [REALTIME] New receipt D90037150334891028480 | 2025-07-14 11:06:50 | ÈπøËßíÂ∑∑ | 7.00\n",
      "üìÑ [REALTIME] Scraping page 2‚Ä¶\n",
      "üéâ New receipts!\n",
      "üìÑ [REALTIME] Scraping page 1‚Ä¶\n",
      "‚úîÔ∏è [REALTIME] New receipt 250714#13761773458 | 2025-07-14 11:07:55 | Á¶èÂ•àÁâπÁéõÂ•¥Êãâ | 820.00\n",
      "‚úîÔ∏è [REALTIME] New receipt 8044040208491944418 | 2025-07-14 11:07:36 | ÁªøÂ°îÂ∏ÇÈõÜ | 64.30\n",
      "üìÑ [REALTIME] Scraping page 2‚Ä¶\n",
      "üéâ New receipts!\n",
      "üìÑ [REALTIME] Scraping page 1‚Ä¶\n",
      "‚úîÔ∏è [REALTIME] New receipt 250714#64 | 2025-07-14 11:10:02 | Á±≥ÊùëÊãåÈ•≠Â†ÇÈ£ü | 20.00\n",
      "‚úîÔ∏è [REALTIME] New receipt N8622_17524623986 | 2025-07-14 11:09:32 |  | 539.00\n",
      "‚úîÔ∏è [REALTIME] New receipt P018LS-2025-07-14-005 | 2025-07-14 11:09:29 | ÈùíÁ®öÊä§ÊâãÈúú | 205.00\n",
      "‚úîÔ∏è [REALTIME] New receipt 326098322413 | 2025-07-14 11:09:10 | ÁªøÂ°îÂ∏ÇÈõÜ | 33.30\n",
      "‚úîÔ∏è [REALTIME] New receipt 37003250714110853196 | 2025-07-14 11:09:08 | ÁªøÂ°îÂ∏ÇÈõÜ | 57.38\n",
      "üìÑ [REALTIME] Scraping page 2‚Ä¶\n",
      "üéâ New receipts!\n",
      "üìÑ [REALTIME] Scraping page 1‚Ä¶\n",
      "‚úîÔ∏è [REALTIME] New receipt 250714#68 | 2025-07-14 11:11:45 | Á±≥ÊùëÊãåÈ•≠Â†ÇÈ£ü | 19.90\n",
      "‚úîÔ∏è [REALTIME] New receipt 250714#67 | 2025-07-14 11:11:31 | Á±≥ÊùëÊãåÈ•≠Â†ÇÈ£ü | 19.20\n",
      "‚úîÔ∏è [REALTIME] New receipt 250714#66 | 2025-07-14 11:11:09 | Á±≥ÊùëÊãåÈ•≠Â†ÇÈ£ü | 18.89\n",
      "‚úîÔ∏è [REALTIME] New receipt 202507141110324730002 | 2025-07-14 11:11:06 | Ë•øÂ°îÊòüÁêÉ | 8.80\n",
      "‚úîÔ∏è [REALTIME] New receipt 8006390208463350068 | 2025-07-14 11:11:01 | ÁªøÂ°îÂ∏ÇÈõÜ | 56.00\n",
      "‚úîÔ∏è [REALTIME] New receipt 250714#65 | 2025-07-14 11:10:51 | Á±≥ÊùëÊãåÈ•≠Â†ÇÈ£ü | 24.40\n",
      "‚úîÔ∏è [REALTIME] New receipt 8002716042249872839 | 2025-07-14 11:10:30 | ÁªøÂ°îÂ∏ÇÈõÜ | 52.50\n",
      "‚úîÔ∏è [REALTIME] New receipt 326163372842 | 2025-07-14 11:10:20 | ÁªøÂ°îÂ∏ÇÈõÜ | 41.00\n",
      "üìÑ [REALTIME] Scraping page 2‚Ä¶\n"
     ]
    },
    {
     "ename": "InvalidSessionIdException",
     "evalue": "Message: invalid session id: session deleted as the browser has closed the connection\nfrom disconnected: unable to send message to renderer\n  (Session info: chrome=138.0.7204.101); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalidsessionidexception\nStacktrace:\n\tGetHandleVerifier [0x0x7ff684822585+76709]\n\tGetHandleVerifier [0x0x7ff6848225e0+76800]\n\t(No symbol) [0x0x7ff6845f9b2a]\n\t(No symbol) [0x0x7ff6845e62a1]\n\t(No symbol) [0x0x7ff6845e620c]\n\t(No symbol) [0x0x7ff6845e499c]\n\t(No symbol) [0x0x7ff6845e565f]\n\t(No symbol) [0x0x7ff68460d691]\n\t(No symbol) [0x0x7ff684610369]\n\t(No symbol) [0x0x7ff68460ea43]\n\t(No symbol) [0x0x7ff684602221]\n\t(No symbol) [0x0x7ff6846000df]\n\t(No symbol) [0x0x7ff68460456c]\n\t(No symbol) [0x0x7ff68460463f]\n\t(No symbol) [0x0x7ff684649ac6]\n\t(No symbol) [0x0x7ff6846781ba]\n\t(No symbol) [0x0x7ff6846428c6]\n\t(No symbol) [0x0x7ff6846783d0]\n\t(No symbol) [0x0x7ff6846a03ff]\n\t(No symbol) [0x0x7ff684677f93]\n\t(No symbol) [0x0x7ff6846410e1]\n\t(No symbol) [0x0x7ff684641e73]\n\tGetHandleVerifier [0x0x7ff684b02dad+3093453]\n\tGetHandleVerifier [0x0x7ff684afd13d+3069789]\n\tGetHandleVerifier [0x0x7ff684b1ba7d+3195037]\n\tGetHandleVerifier [0x0x7ff68483c2ce+182510]\n\tGetHandleVerifier [0x0x7ff684843bef+213519]\n\tGetHandleVerifier [0x0x7ff68482adc4+111588]\n\tGetHandleVerifier [0x0x7ff68482af79+112025]\n\tGetHandleVerifier [0x0x7ff6848124f8+11032]\n\tBaseThreadInitThunk [0x0x7ffd4281e8d7+23]\n\tRtlUserThreadStart [0x0x7ffd4453c34c+44]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidSessionIdException\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 258\u001b[39m\n\u001b[32m    255\u001b[39m         time.sleep(refresh_seconds)\n\u001b[32m    257\u001b[39m scrape_backwards_from_current()\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[43mrealtime_scrape_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefresh_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust as needed\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 250\u001b[39m, in \u001b[36mrealtime_scrape_loop\u001b[39m\u001b[34m(refresh_seconds)\u001b[39m\n\u001b[32m    247\u001b[39m page, cycle_new = \u001b[32m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# keep going while this page yielded something new\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mscrape_table_realtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    251\u001b[39m     cycle_new = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    252\u001b[39m     page += \u001b[32m1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 191\u001b[39m, in \u001b[36mscrape_table_realtime\u001b[39m\u001b[34m(page_number)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tds \u001b[38;5;129;01mor\u001b[39;00m tds[\u001b[32m0\u001b[39m].text.strip() == \u001b[33m\"\u001b[39m\u001b[33mÈááÈõÜÂâçÁ´Ø\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m raw_trans  = \u001b[43mtds\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m.strip()\n\u001b[32m    192\u001b[39m trans_time = datetime.strptime(raw_trans, \u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# if it‚Äôs too old, skip‚Äîbut don't break\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Point Detection\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:110\u001b[39m, in \u001b[36mWebElement.text\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtext\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     99\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"The text of the element.\u001b[39;00m\n\u001b[32m    100\u001b[39m \n\u001b[32m    101\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    108\u001b[39m \u001b[33;03m    >>> print(element.text)\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGET_ELEMENT_TEXT\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Point Detection\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:573\u001b[39m, in \u001b[36mWebElement._execute\u001b[39m\u001b[34m(self, command, params)\u001b[39m\n\u001b[32m    571\u001b[39m     params = {}\n\u001b[32m    572\u001b[39m params[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._id\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Point Detection\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:454\u001b[39m, in \u001b[36mWebDriver.execute\u001b[39m\u001b[34m(self, driver_command, params)\u001b[39m\n\u001b[32m    451\u001b[39m response = cast(RemoteConnection, \u001b[38;5;28mself\u001b[39m.command_executor).execute(driver_command, params)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m     response[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._unwrap_value(response.get(\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Point Detection\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:232\u001b[39m, in \u001b[36mErrorHandler.check_response\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    230\u001b[39m         alert_text = value[\u001b[33m\"\u001b[39m\u001b[33malert\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[31mInvalidSessionIdException\u001b[39m: Message: invalid session id: session deleted as the browser has closed the connection\nfrom disconnected: unable to send message to renderer\n  (Session info: chrome=138.0.7204.101); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalidsessionidexception\nStacktrace:\n\tGetHandleVerifier [0x0x7ff684822585+76709]\n\tGetHandleVerifier [0x0x7ff6848225e0+76800]\n\t(No symbol) [0x0x7ff6845f9b2a]\n\t(No symbol) [0x0x7ff6845e62a1]\n\t(No symbol) [0x0x7ff6845e620c]\n\t(No symbol) [0x0x7ff6845e499c]\n\t(No symbol) [0x0x7ff6845e565f]\n\t(No symbol) [0x0x7ff68460d691]\n\t(No symbol) [0x0x7ff684610369]\n\t(No symbol) [0x0x7ff68460ea43]\n\t(No symbol) [0x0x7ff684602221]\n\t(No symbol) [0x0x7ff6846000df]\n\t(No symbol) [0x0x7ff68460456c]\n\t(No symbol) [0x0x7ff68460463f]\n\t(No symbol) [0x0x7ff684649ac6]\n\t(No symbol) [0x0x7ff6846781ba]\n\t(No symbol) [0x0x7ff6846428c6]\n\t(No symbol) [0x0x7ff6846783d0]\n\t(No symbol) [0x0x7ff6846a03ff]\n\t(No symbol) [0x0x7ff684677f93]\n\t(No symbol) [0x0x7ff6846410e1]\n\t(No symbol) [0x0x7ff684641e73]\n\tGetHandleVerifier [0x0x7ff684b02dad+3093453]\n\tGetHandleVerifier [0x0x7ff684afd13d+3069789]\n\tGetHandleVerifier [0x0x7ff684b1ba7d+3195037]\n\tGetHandleVerifier [0x0x7ff68483c2ce+182510]\n\tGetHandleVerifier [0x0x7ff684843bef+213519]\n\tGetHandleVerifier [0x0x7ff68482adc4+111588]\n\tGetHandleVerifier [0x0x7ff68482af79+112025]\n\tGetHandleVerifier [0x0x7ff6848124f8+11032]\n\tBaseThreadInitThunk [0x0x7ffd4281e8d7+23]\n\tRtlUserThreadStart [0x0x7ffd4453c34c+44]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# ‚Üê‚îÄ‚îÄ ADD THIS HERE ‚îÄ‚îÄ‚Üí\n",
    "# Will hold all receipts we‚Äôve already seen\n",
    "transactions = {}\n",
    "last_time = datetime.min\n",
    "# Initialize WebDriver and go to the target URL first\n",
    "# Example: driver = webdriver.Chrome()\n",
    "\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# ‚úÖ Get current page number\n",
    "def get_current_page_number():\n",
    "    try:\n",
    "        current_li = wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, '//li[contains(@class, \"pageItemActive\")]')\n",
    "        ))\n",
    "        return int(current_li.get_attribute(\"page-data\"))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to get current page number:\", e)\n",
    "        return -1\n",
    "\n",
    "# ‚úÖ Jump to a specific page (retry until success)\n",
    "def jump_to_target_page(page_number):\n",
    "    while True:\n",
    "        try:\n",
    "            input_box = wait.until(EC.presence_of_element_located((By.ID, \"whichPage\")))\n",
    "            confirm_btn = driver.find_element(By.ID, \"confirmId\")\n",
    "\n",
    "            input_box.clear()\n",
    "            input_box.send_keys(str(page_number))\n",
    "            confirm_btn.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            current_page = get_current_page_number()\n",
    "            if current_page == page_number:\n",
    "                print(f\"‚úÖ Jumped to page {page_number}\")\n",
    "                return\n",
    "            else:\n",
    "                print(f\"‚Ü™Ô∏è Still on page {current_page}, retrying page {page_number}...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå Failed to jump:\", e)\n",
    "            time.sleep(1)\n",
    "\n",
    "def scrape_table(page_number):\n",
    "    \"\"\"\n",
    "    Scrape page_number.\n",
    "    Returns True if ANY new receipt was saved, False if all were duplicates or no rows.\n",
    "    \"\"\"\n",
    "    print(f\"üìÑ Scraping page {page_number}...\")\n",
    "    rows = wait.until(EC.presence_of_all_elements_located(\n",
    "        (By.XPATH, '//table[@class=\"table\" and @hd-freezer-header=\"\"]/tbody/tr')\n",
    "    ))\n",
    "\n",
    "    # Pre-scan receipts on this page\n",
    "    raw_receipts = []\n",
    "    for row in rows:\n",
    "        tds = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if not tds or tds[0].text.strip() == \"ÈááÈõÜÂâçÁ´Ø\":\n",
    "            continue\n",
    "        raw_receipts.append(tds[4].text.strip())\n",
    "\n",
    "    # If there are no rows or they're all duplicates, bail out\n",
    "    if not raw_receipts or all(r in transactions for r in raw_receipts):\n",
    "        print(f\"‚ö†Ô∏è No new receipts on page {page_number}\")\n",
    "        return False\n",
    "\n",
    "    # Otherwise process each row, skipping individual duplicates\n",
    "    new_found = False\n",
    "    for row in rows:\n",
    "        tds = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if not tds or tds[0].text.strip() == \"ÈááÈõÜÂâçÁ´Ø\":\n",
    "            continue\n",
    "\n",
    "        raw_receipt = tds[4].text.strip()\n",
    "\n",
    "        # ‚Üê‚îÄ‚îÄ DUPLICATE CHECK: skip if already scraped ‚îÄ‚îÄ‚Üí\n",
    "        if raw_receipt in transactions:\n",
    "            print(f\"‚ö†Ô∏è Skipping duplicate receipt {raw_receipt}\")\n",
    "            continue\n",
    "\n",
    "        # ‚Ä¶ your cleaning/parsing ‚Ä¶\n",
    "        shop = re.sub(r'\\[.*?\\]', '', tds[1].text.strip())\n",
    "        shop = ''.join(re.findall(r'[\\u4e00-\\u9fff]+', shop))\n",
    "\n",
    "        settle_dt  = datetime.strptime(tds[2].text.strip(), \"%Y-%m-%d\").date()\n",
    "        trans_time = datetime.strptime(tds[12].text.strip(), \"%Y-%m-%d %H:%M:%S\")\n",
    "        amount     = float(tds[5].text.strip().replace(\",\", \"\"))\n",
    "\n",
    "        # ‚Üê‚îÄ‚îÄ STORE the new receipt ‚îÄ‚îÄ‚Üí\n",
    "        transactions[raw_receipt] = {\n",
    "            \"shop\":       shop,\n",
    "            \"settle_dt\":  settle_dt,\n",
    "            \"trans_time\": trans_time,\n",
    "            \"amount\":     amount\n",
    "        }\n",
    "\n",
    "        # ‚Üê‚îÄ‚îÄ PRINT new receipt ‚îÄ‚îÄ‚Üí\n",
    "        print(f\"‚úîÔ∏è Saved Receipt: {raw_receipt} | Shop: {shop} | \"\n",
    "              f\"Date: {settle_dt} | Time: {trans_time.time()} | \"\n",
    "              f\"Amount: {amount:.2f}\")\n",
    "\n",
    "        new_found = True\n",
    "\n",
    "    return new_found\n",
    "\n",
    "def scrape_table_history(page_number):\n",
    "    print(f\"üìÑ [HISTORY] Scraping page {page_number}‚Ä¶\")\n",
    "    rows = wait.until(EC.presence_of_all_elements_located(\n",
    "        (By.XPATH, '//table[@class=\"table\"][ @hd-freezer-header=\"\"]/tbody/tr')\n",
    "    ))\n",
    "\n",
    "    new_found = False\n",
    "    for row in rows:\n",
    "        tds = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if not tds or tds[0].text.strip() == \"ÈááÈõÜÂâçÁ´Ø\":\n",
    "            continue\n",
    "\n",
    "        raw_receipt = tds[4].text.strip()\n",
    "        if raw_receipt in transactions:\n",
    "            # ‚Üê‚îÄ‚îÄ Add this print so history shows duplicate skips ‚îÄ‚îÄ‚Üí\n",
    "            print(f\"‚ö†Ô∏è [HISTORY] Skipping duplicate receipt {raw_receipt}\")\n",
    "            continue\n",
    "        # cleaning/parsing\n",
    "        shop       = re.sub(r'\\[.*?\\]', '', tds[1].text.strip())\n",
    "        shop       = ''.join(re.findall(r'[\\u4e00-\\u9fff]+', shop))\n",
    "        settle_dt  = datetime.strptime(tds[2].text.strip(), \"%Y-%m-%d\").date()\n",
    "        trans_time = datetime.strptime(tds[12].text.strip(), \"%Y-%m-%d %H:%M:%S\")\n",
    "        raw_amt    = tds[5].text.strip().replace(\",\", \"\")\n",
    "        amount     = float(raw_amt) if raw_amt else 0.0\n",
    "\n",
    "        # store\n",
    "        transactions[raw_receipt] = {\n",
    "            \"shop\":       shop,\n",
    "            \"settle_dt\":  settle_dt,\n",
    "            \"trans_time\": trans_time,\n",
    "            \"amount\":     amount\n",
    "        }\n",
    "        print(f\"‚úîÔ∏è [HISTORY] Saved {raw_receipt} @ {trans_time}\")\n",
    "        new_found = True\n",
    "\n",
    "    return new_found\n",
    "\n",
    "# ‚úÖ Main loop: scrape current page, then go backward\n",
    "def scrape_backwards_from_current():\n",
    "    target_page = get_current_page_number()\n",
    "    if target_page == -1:\n",
    "        print(\"‚ùå Cannot detect starting page.\")\n",
    "        return\n",
    "\n",
    "    while target_page >= 1:\n",
    "        if target_page != get_current_page_number():\n",
    "            jump_to_target_page(target_page)\n",
    "        scrape_table_history(target_page)\n",
    "        target_page -= 1\n",
    "\n",
    "    print(\"‚úÖ Finished history scrape.\")\n",
    "\n",
    "    # initialize last_time from everything we‚Äôve just scraped\n",
    "    global last_time\n",
    "    if transactions:\n",
    "        last_time = max(tx[\"trans_time\"] for tx in transactions.values())\n",
    "    print(\"üîñ last_time set to\", last_time)\n",
    "def scrape_table_realtime(page_number):\n",
    "    \"\"\"\n",
    "    Scrape page_number, but only STOP PAGING when NO new rows\n",
    "    (by time) are found on the entire page.\n",
    "    Returns True if ANY new receipt was saved, False otherwise.\n",
    "    \"\"\"\n",
    "    global last_time\n",
    "    print(f\"üìÑ [REALTIME] Scraping page {page_number}‚Ä¶\")\n",
    "\n",
    "    rows = wait.until(EC.presence_of_all_elements_located(\n",
    "        (By.XPATH, '//table[@class=\"table\" and @hd-freezer-header=\"\"]/tbody/tr')\n",
    "    ))\n",
    "\n",
    "    new_found   = False\n",
    "    page_max_ts = last_time   # track the newest time we see this page\n",
    "\n",
    "    for row in rows:\n",
    "        tds = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if not tds or tds[0].text.strip() == \"ÈááÈõÜÂâçÁ´Ø\":\n",
    "            continue\n",
    "\n",
    "        raw_trans  = tds[12].text.strip()\n",
    "        trans_time = datetime.strptime(raw_trans, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        # if it‚Äôs too old, skip‚Äîbut don't break\n",
    "        if trans_time < last_time:\n",
    "            continue\n",
    "\n",
    "        # otherwise it's a candidate\n",
    "        raw_receipt = tds[4].text.strip()\n",
    "        if raw_receipt in transactions:\n",
    "            continue\n",
    "\n",
    "        # clean & parse\n",
    "        shop       = re.sub(r'\\[.*?\\]', '', tds[1].text.strip())\n",
    "        shop       = ''.join(re.findall(r'[\\u4e00-\\u9fff]+', shop))\n",
    "        settle_dt  = datetime.strptime(tds[2].text.strip(), \"%Y-%m-%d\").date()\n",
    "        raw_amt    = tds[5].text.strip().replace(\",\", \"\")\n",
    "        amount     = float(raw_amt) if raw_amt else 0.0\n",
    "\n",
    "        # store\n",
    "        transactions[raw_receipt] = {\n",
    "            \"shop\":       shop,\n",
    "            \"settle_dt\":  settle_dt,\n",
    "            \"trans_time\": trans_time,\n",
    "            \"amount\":     amount\n",
    "        }\n",
    "        print(\n",
    "            f\"‚úîÔ∏è [REALTIME] New receipt {raw_receipt} | \"\n",
    "            f\"{trans_time} | {shop} | {amount:.2f}\"\n",
    "        )\n",
    "\n",
    "        new_found = True\n",
    "        # remember the newest timestamp on this page\n",
    "        if trans_time > page_max_ts:\n",
    "            page_max_ts = trans_time\n",
    "\n",
    "    # if we saw any new receipts, advance our watermark\n",
    "    if new_found:\n",
    "        last_time = page_max_ts\n",
    "\n",
    "    return new_found\n",
    "\n",
    "# ‚úÖ Run\n",
    "def get_last_page_number():\n",
    "    try:\n",
    "        li = wait.until(EC.presence_of_element_located(\n",
    "            (By.XPATH, '//li[@page-rel=\"lastpage\"]')))\n",
    "        return int(li.get_attribute(\"page-data\"))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to get last page number:\", e)\n",
    "        return -1\n",
    "\n",
    "# ---------- NEW real-time loop ----------\n",
    "def realtime_scrape_loop(refresh_seconds=60):\n",
    "    while True:\n",
    "        driver.refresh(); time.sleep(6)\n",
    "        page, cycle_new = 1, False\n",
    "\n",
    "        # keep going while this page yielded something new\n",
    "        while scrape_table_realtime(page):\n",
    "            cycle_new = True\n",
    "            page += 1\n",
    "\n",
    "        print(\"üéâ New receipts!\" if cycle_new else \"‚ö†Ô∏è No new receipts.\")\n",
    "        time.sleep(refresh_seconds)\n",
    "\n",
    "scrape_backwards_from_current()\n",
    "realtime_scrape_loop(refresh_seconds=60)  # Adjust as needed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
